---
layout: single
title: The best NLP papers of 2019
permalink: /nlp/papers/2019/
---

<div>
<p class="featured_snippet">The best NLP papers of 2019 include "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "HuggingFace's Transformers: State-of-the-art Natural Language Processing", and "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension". These papers have made significant contributions to the field of NLP.</p>
{% for paper in site.data.papers_2019 %}
    <h4>{{ paper.no }}. <a href="{{ paper.url }}" style="text-decoration:none">{{ paper.title }}</a></h4>

    <p class="cites"> {{ paper.cites }} citations</p>

    {% if paper.abstract != null %}
    <div class="abstract">
    <p>{{ paper.abstract }}</p>
    </div>
    {% endif %}
{% endfor %}
</div>

