[{"url": "http://arxiv.org/abs/1706.03762v5", "title": "Attention Is All You Need", "cites": 47033}, {"url": "http://arxiv.org/abs/1810.04805v2", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language\n  Understanding", "cites": 43750}, {"url": "http://arxiv.org/abs/1310.4546v1", "title": "Distributed Representations of Words and Phrases and their\n  Compositionality", "cites": 28053}, {"url": "http://arxiv.org/abs/1301.3781v3", "title": "Efficient Estimation of Word Representations in Vector Space", "cites": 24238}, {"url": "http://arxiv.org/abs/1409.0473v7", "title": "Neural Machine Translation by Jointly Learning to Align and Translate", "cites": 21395}, {"url": "http://arxiv.org/abs/1406.1078v3", "title": "Learning Phrase Representations using RNN Encoder-Decoder for\n  Statistical Machine Translation", "cites": 16952}, {"url": "http://arxiv.org/abs/1409.3215v3", "title": "Sequence to Sequence Learning with Neural Networks", "cites": 16223}, {"url": "http://arxiv.org/abs/1408.5882v2", "title": "Convolutional Neural Networks for Sentence Classification", "cites": 11021}, {"url": "http://arxiv.org/abs/1907.11692v1", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "cites": 9923}, {"url": "http://arxiv.org/abs/1802.05365v2", "title": "Deep contextualized word representations", "cites": 8915}, {"url": "http://arxiv.org/abs/1405.4053v2", "title": "Distributed Representations of Sentences and Documents", "cites": 7658}, {"url": "http://arxiv.org/abs/1607.04606v2", "title": "Enriching Word Vectors with Subword Information", "cites": 7370}, {"url": "http://arxiv.org/abs/1303.5778v1", "title": "Speech Recognition with Deep Recurrent Neural Networks", "cites": 7357}, {"url": "http://arxiv.org/abs/2005.14165v4", "title": "Language Models are Few-Shot Learners", "cites": 7025}, {"url": "http://arxiv.org/abs/1508.04025v5", "title": "Effective Approaches to Attention-based Neural Machine Translation", "cites": 6419}, {"url": "http://arxiv.org/abs/1910.10683v3", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text\n  Transformer", "cites": 5465}, {"url": "http://arxiv.org/abs/1508.07909v5", "title": "Neural Machine Translation of Rare Words with Subword Units", "cites": 5367}, {"url": "http://arxiv.org/abs/1609.08144v2", "title": "Google's Neural Machine Translation System: Bridging the Gap between\n  Human and Machine Translation", "cites": 5182}, {"url": "http://arxiv.org/abs/1906.08237v2", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding", "cites": 5123}, {"url": "http://arxiv.org/abs/1606.05250v3", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "cites": 4933}, {"url": "http://arxiv.org/abs/1409.1259v2", "title": "On the Properties of Neural Machine Translation: Encoder-Decoder\n  Approaches", "cites": 4698}, {"url": "http://arxiv.org/abs/1509.01626v3", "title": "Character-level Convolutional Networks for Text Classification", "cites": 3956}, {"url": "http://arxiv.org/abs/1910.13461v1", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language\n  Generation, Translation, and Comprehension", "cites": 3536}, {"url": "http://arxiv.org/abs/1909.11942v6", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language\n  Representations", "cites": 3451}, {"url": "http://arxiv.org/abs/1607.01759v3", "title": "Bag of Tricks for Efficient Text Classification", "cites": 3411}, {"url": "http://arxiv.org/abs/1505.00468v7", "title": "VQA: Visual Question Answering", "cites": 3389}, {"url": "http://arxiv.org/abs/1308.0850v5", "title": "Generating Sequences With Recurrent Neural Networks", "cites": 3378}, {"url": "http://arxiv.org/abs/1910.03771v5", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing", "cites": 3321}, {"url": "http://arxiv.org/abs/1804.07461v3", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language\n  Understanding", "cites": 3262}, {"url": "http://arxiv.org/abs/1404.2188v1", "title": "A Convolutional Neural Network for Modelling Sentences", "cites": 3201}, {"url": "http://arxiv.org/abs/1603.01360v3", "title": "Neural Architectures for Named Entity Recognition", "cites": 3196}, {"url": "http://arxiv.org/abs/1508.05326v1", "title": "A large annotated corpus for learning natural language inference", "cites": 2878}, {"url": "http://arxiv.org/abs/1910.01108v4", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and\n  lighter", "cites": 2855}, {"url": "http://arxiv.org/abs/1704.04368v2", "title": "Get To The Point: Summarization with Pointer-Generator Networks", "cites": 2808}, {"url": "http://arxiv.org/abs/1508.01991v1", "title": "Bidirectional LSTM-CRF Models for Sequence Tagging", "cites": 2807}, {"url": "http://arxiv.org/abs/1506.03340v3", "title": "Teaching Machines to Read and Comprehend", "cites": 2698}, {"url": "http://arxiv.org/abs/1705.03122v3", "title": "Convolutional Sequence to Sequence Learning", "cites": 2669}, {"url": "http://arxiv.org/abs/1503.00075v3", "title": "Improved Semantic Representations From Tree-Structured Long Short-Term\n  Memory Networks", "cites": 2665}, {"url": "http://arxiv.org/abs/1806.09055v2", "title": "DARTS: Differentiable Architecture Search", "cites": 2607}, {"url": "http://arxiv.org/abs/1908.10084v1", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks", "cites": 2576}, {"url": "http://arxiv.org/abs/1411.5726v2", "title": "CIDEr: Consensus-based Image Description Evaluation", "cites": 2537}, {"url": "http://arxiv.org/abs/1901.08746v4", "title": "BioBERT: a pre-trained biomedical language representation model for\n  biomedical text mining", "cites": 2497}, {"url": "http://arxiv.org/abs/1704.05426v4", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through\n  Inference", "cites": 2450}, {"url": "http://arxiv.org/abs/1512.02595v1", "title": "Deep Speech 2: End-to-End Speech Recognition in English and Mandarin", "cites": 2448}, {"url": "http://arxiv.org/abs/1911.02116v2", "title": "Unsupervised Cross-lingual Representation Learning at Scale", "cites": 2443}, {"url": "http://arxiv.org/abs/1509.00685v2", "title": "A Neural Attention Model for Abstractive Sentence Summarization", "cites": 2272}, {"url": "http://arxiv.org/abs/1803.01271v2", "title": "An Empirical Evaluation of Generic Convolutional and Recurrent Networks\n  for Sequence Modeling", "cites": 2247}, {"url": "http://arxiv.org/abs/1705.02315v5", "title": "ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on\n  Weakly-Supervised Classification and Localization of Common Thorax Diseases", "cites": 2224}, {"url": "http://arxiv.org/abs/1603.01354v5", "title": "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF", "cites": 2186}, {"url": "http://arxiv.org/abs/1901.02860v3", "title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context", "cites": 2147}, {"url": "http://arxiv.org/abs/1708.02709v8", "title": "Recent Trends in Deep Learning Based Natural Language Processing", "cites": 2101}, {"url": "http://arxiv.org/abs/1506.07503v1", "title": "Attention-Based Models for Speech Recognition", "cites": 2062}, {"url": "http://arxiv.org/abs/1506.06726v1", "title": "Skip-Thought Vectors", "cites": 2040}, {"url": "http://arxiv.org/abs/1802.03268v2", "title": "Efficient Neural Architecture Search via Parameter Sharing", "cites": 1978}, {"url": "http://arxiv.org/abs/1904.08779v3", "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech\n  Recognition", "cites": 1971}, {"url": "http://arxiv.org/abs/1511.06709v4", "title": "Improving Neural Machine Translation Models with Monolingual Data", "cites": 1951}, {"url": "http://arxiv.org/abs/1904.01038v1", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling", "cites": 1905}, {"url": "http://arxiv.org/abs/1511.06349v4", "title": "Generating Sentences from a Continuous Space", "cites": 1903}, {"url": "http://arxiv.org/abs/1607.06520v1", "title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word\n  Embeddings", "cites": 1863}, {"url": "http://arxiv.org/abs/1808.06226v1", "title": "SentencePiece: A simple and language independent subword tokenizer and\n  detokenizer for Neural Text Processing", "cites": 1853}, {"url": "http://arxiv.org/abs/1412.6575v4", "title": "Embedding Entities and Relations for Learning and Inference in Knowledge\n  Bases", "cites": 1839}, {"url": "http://arxiv.org/abs/1611.01603v6", "title": "Bidirectional Attention Flow for Machine Comprehension", "cites": 1837}, {"url": "http://arxiv.org/abs/1901.07291v1", "title": "Cross-lingual Language Model Pretraining", "cites": 1770}, {"url": "http://arxiv.org/abs/1602.06023v5", "title": "Abstractive Text Summarization Using Sequence-to-Sequence RNNs and\n  Beyond", "cites": 1732}, {"url": "http://arxiv.org/abs/1308.6297v1", "title": "Crowdsourcing a Word-Emotion Association Lexicon", "cites": 1704}, {"url": "http://arxiv.org/abs/1908.02265v1", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for\n  Vision-and-Language Tasks", "cites": 1697}, {"url": "http://arxiv.org/abs/1412.5567v2", "title": "Deep Speech: Scaling up end-to-end speech recognition", "cites": 1677}, {"url": "http://arxiv.org/abs/1703.03130v1", "title": "A Structured Self-attentive Sentence Embedding", "cites": 1675}, {"url": "http://arxiv.org/abs/1705.02364v5", "title": "Supervised Learning of Universal Sentence Representations from Natural\n  Language Inference Data", "cites": 1668}, {"url": "http://arxiv.org/abs/1712.05884v2", "title": "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram\n  Predictions", "cites": 1664}, {"url": "http://arxiv.org/abs/1506.06724v1", "title": "Aligning Books and Movies: Towards Story-like Visual Explanations by\n  Watching Movies and Reading Books", "cites": 1662}, {"url": "http://arxiv.org/abs/2003.10555v1", "title": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than\n  Generators", "cites": 1660}, {"url": "http://arxiv.org/abs/1806.03822v1", "title": "Know What You Don't Know: Unanswerable Questions for SQuAD", "cites": 1614}, {"url": "http://arxiv.org/abs/1510.03055v3", "title": "A Diversity-Promoting Objective Function for Neural Conversation Models", "cites": 1593}, {"url": "http://arxiv.org/abs/1611.04558v2", "title": "Google's Multilingual Neural Machine Translation System: Enabling\n  Zero-Shot Translation", "cites": 1580}, {"url": "http://arxiv.org/abs/1511.02274v2", "title": "Stacked Attention Networks for Image Question Answering", "cites": 1579}, {"url": "http://arxiv.org/abs/1506.05869v3", "title": "A Neural Conversational Model", "cites": 1578}, {"url": "http://arxiv.org/abs/1703.04009v1", "title": "Automated Hate Speech Detection and the Problem of Offensive Language", "cites": 1554}, {"url": "http://arxiv.org/abs/1506.03099v3", "title": "Scheduled Sampling for Sequence Prediction with Recurrent Neural\n  Networks", "cites": 1549}, {"url": "http://arxiv.org/abs/1507.04808v3", "title": "Building End-To-End Dialogue Systems Using Generative Hierarchical\n  Neural Network Models", "cites": 1531}, {"url": "http://arxiv.org/abs/1612.03975v2", "title": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge", "cites": 1526}, {"url": "http://arxiv.org/abs/1608.07187v4", "title": "Semantics derived automatically from language corpora contain human-like\n  biases", "cites": 1526}, {"url": "http://arxiv.org/abs/1709.03815v1", "title": "OpenNMT: Open-source Toolkit for Neural Machine Translation", "cites": 1492}, {"url": "http://arxiv.org/abs/1703.04247v1", "title": "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction", "cites": 1492}, {"url": "http://arxiv.org/abs/1701.02810v2", "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation", "cites": 1492}, {"url": "http://arxiv.org/abs/1612.08083v3", "title": "Language Modeling with Gated Convolutional Networks", "cites": 1485}, {"url": "http://arxiv.org/abs/1508.06615v4", "title": "Character-Aware Neural Language Models", "cites": 1476}, {"url": "http://arxiv.org/abs/1904.09675v3", "title": "BERTScore: Evaluating Text Generation with BERT", "cites": 1464}, {"url": "http://arxiv.org/abs/1511.08308v5", "title": "Named Entity Recognition with Bidirectional LSTM-CNNs", "cites": 1456}, {"url": "http://arxiv.org/abs/2006.11477v3", "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech\n  Representations", "cites": 1436}, {"url": "http://arxiv.org/abs/1906.02243v1", "title": "Energy and Policy Considerations for Deep Learning in NLP", "cites": 1427}, {"url": "http://arxiv.org/abs/1612.06890v1", "title": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary\n  Visual Reasoning", "cites": 1426}, {"url": "http://arxiv.org/abs/1309.4168v1", "title": "Exploiting Similarities among Languages for Machine Translation", "cites": 1426}, {"url": "http://arxiv.org/abs/1804.08771v2", "title": "A Call for Clarity in Reporting BLEU Scores", "cites": 1390}, {"url": "http://arxiv.org/abs/1612.00837v3", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in\n  Visual Question Answering", "cites": 1389}, {"url": "http://arxiv.org/abs/1409.2944v2", "title": "Collaborative Deep Learning for Recommender Systems", "cites": 1384}, {"url": "http://arxiv.org/abs/1504.00325v2", "title": "Microsoft COCO Captions: Data Collection and Evaluation Server", "cites": 1371}, {"url": "http://arxiv.org/abs/1704.00051v2", "title": "Reading Wikipedia to Answer Open-Domain Questions", "cites": 1360}, {"url": "http://arxiv.org/abs/1511.06732v7", "title": "Sequence Level Training with Recurrent Neural Networks", "cites": 1325}, {"url": "http://arxiv.org/abs/1402.3722v1", "title": "word2vec Explained: deriving Mikolov et al.'s negative-sampling\n  word-embedding method", "cites": 1325}]