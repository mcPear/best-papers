The best NLP papers of 2013 include "Distributed Representations of Words and Phrases and their Compositionality" and "Efficient Estimation of Word Representations in Vector Space", both focusing on improving the quality and speed of training word vectors. Other notable papers cover topics like speech recognition with deep recurrent neural networks, generating sequences with recurrent neural networks, and exploiting similarities among languages for machine translation.