The best NLP papers of 2017 include "Attention Is All You Need" with 77,761 citations, "Get To The Point: Summarization with Pointer-Generator Networks" with 3,391 citations, and "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference" with 3,382 citations. These papers introduced innovative concepts like the Transformer network architecture, pointer-generator networks for text summarization, and the Multi-Genre Natural Language Inference corpus.